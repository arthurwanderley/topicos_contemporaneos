{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Equipe:\n",
        "\n",
        "Arthur Wanderley Ferreira dos Santos - awfs@cesar.school\n",
        "\n",
        "Thiago Wanderley Amorim - twa@cesar.school"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TPWi6rGqRRdd",
        "outputId": "d7ffd053-f958-4041-cce7-e7dbe8f58a08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.14)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.59.6)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.11)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.29)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.5)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.2.10)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.5)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (24.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.14)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain) (3.0.0)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.14)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.11)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.14 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.14)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.29)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.2.10)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.25.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.14->langchain_community) (0.3.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.14->langchain_community) (2.10.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (3.10.14)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain_community) (2.27.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain openai\n",
        "!pip install langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oc00w-tcRB60",
        "outputId": "533a3f10-7ca3-423b-b14e-3ec3426b3823"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caZcUP-bRB61"
      },
      "source": [
        "## Modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjP0_pSjRB61",
        "outputId": "6bf6d3b8-587f-4638-d926-04f104ec5a2a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-5c83e435c0d9>:3: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm = ChatOpenAI(model=\"gpt-4o-mini\")\n"
          ]
        }
      ],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqDsCPuARB61",
        "outputId": "af894a85-2423-4a01-dae9-355b4b78983c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content='Olá! Como posso ajudar você hoje?' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'stop', 'logprobs': None} id='run-585a7b5a-cd18-4ac1-9694-877b3eb79cfc-0'\n"
          ]
        }
      ],
      "source": [
        "response = llm.invoke(\"Olá\")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRiJrIe2RB61"
      },
      "source": [
        "## Prompts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KLVsK87RB62"
      },
      "source": [
        "### Templates Simples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwvZgNIYRB62",
        "outputId": "55f6cbb7-c9e8-49ab-be5d-53c707c4c381"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "messages=[HumanMessage(content='Traduza o seguinte texto para português: Artificial Intelligence is the future!', additional_kwargs={}, response_metadata={})]\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(\"Traduza o seguinte texto para português: {texto}\")\n",
        "\n",
        "prompt = prompt_template.invoke({\"texto\": \"Artificial Intelligence is the future!\"})\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRD55CUIRB62",
        "outputId": "fd995138-c9ae-4dbd-c85d-a8ae1450b0a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A inteligência artificial é o futuro!\n"
          ]
        }
      ],
      "source": [
        "response = llm.invoke(prompt)\n",
        "\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVHU4HTNRB62"
      },
      "source": [
        "### Templates de Mensagens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDV_6x_ORB62",
        "outputId": "a6dc68e7-2d19-436a-9257-f23755a7d650"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content='Olá, como você está?' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 36, 'total_tokens': 43, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None} id='run-e3be829c-b8ec-4ad4-be79-4776ece64872-0'\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"Você é um tradutor de inglês para português. Traduza as mensagens que forem enviadas.\"),\n",
        "    HumanMessage(content=\"Hello, how are you?\"),\n",
        "]\n",
        "\n",
        "# messages = [\n",
        "#     (\"system\", \"Você é um tradutor de inglês para português. Traduza as mensagens que forem enviadas.\"),\n",
        "#     (\"human\", \"Hello, how are you?\"),\n",
        "# ]\n",
        "\n",
        "response = llm.invoke(messages)\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vTF4wIS3RB62"
      },
      "outputs": [],
      "source": [
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"Você é um tradutor de {lingua_origem} para {lingua_destino}. Traduza as mensagens que forem enviadas.\"),\n",
        "        (\"user\", \"{texto}\")\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIWBaAVkRB62",
        "outputId": "e15ad4ca-9dcc-495c-d49f-94b0bc2c9419"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "messages=[SystemMessage(content='Você é um tradutor de inglês para português. Traduza as mensagens que forem enviadas.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hello, how are you?', additional_kwargs={}, response_metadata={})]\n"
          ]
        }
      ],
      "source": [
        "prompt = prompt_template.invoke({\n",
        "    \"lingua_origem\": \"inglês\",\n",
        "    \"lingua_destino\": \"português\",\n",
        "    \"texto\": \"Hello, how are you?\"\n",
        "})\n",
        "\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNgbmzDuRB62",
        "outputId": "db667074-f96c-49e3-b76d-dbfdc222a305"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Olá, como você está?\n"
          ]
        }
      ],
      "source": [
        "response = llm.invoke(prompt)\n",
        "\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22D5qnoaRB62"
      },
      "source": [
        "### Parsers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhktI3JSRB62",
        "outputId": "4684c41e-47db-42cc-cc3a-50ad15458ff4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resposta:\n",
            "content='A capital do Rio Grande do Norte é Natal.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 16, 'total_tokens': 27, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None} id='run-be943820-2d2d-43dd-b659-467138f06b01-0'\n",
            "\n",
            "Saída do parser:\n",
            "A capital do Rio Grande do Norte é Natal.\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "str_parser = StrOutputParser()\n",
        "\n",
        "response = llm.invoke(\"Qual a capital do Rio Grande do Norte?\")\n",
        "output = str_parser.invoke(response)\n",
        "\n",
        "print(\"Resposta:\")\n",
        "print(response)\n",
        "print()\n",
        "print(\"Saída do parser:\")\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFWOuyomRB63",
        "outputId": "0f40ed06-a295-4dfb-cee2-83dad9fe0638"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resposta:\n",
            "content='Aqui está a representação das massas e cargas das partículas que constituem o átomo no formato JSON:\\n\\n```json\\n{\\n  \"próton\": {\\n    \"massa\": \"1.67 x 10^-27 kg\",\\n    \"carga\": \"+1 e\"\\n  },\\n  \"nêutron\": {\\n    \"massa\": \"1.68 x 10^-27 kg\",\\n    \"carga\": \"0 e\"\\n  },\\n  \"elétron\": {\\n    \"massa\": \"9.11 x 10^-31 kg\",\\n    \"carga\": \"-1 e\"\\n  }\\n}\\n```\\n\\nNesta representação, \"e\" representa a carga elementar, que é aproximadamente \\\\( 1.6 \\\\times 10^{-19} \\\\) coulombs.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 159, 'prompt_tokens': 38, 'total_tokens': 197, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None} id='run-10248f7c-37d3-46a4-8c3a-c6dc4d379843-0'\n",
            "\n",
            "Saída do parser:\n",
            "{'próton': {'massa': '1.67 x 10^-27 kg', 'carga': '+1 e'}, 'nêutron': {'massa': '1.68 x 10^-27 kg', 'carga': '0 e'}, 'elétron': {'massa': '9.11 x 10^-31 kg', 'carga': '-1 e'}}\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "\n",
        "json_parser = JsonOutputParser()\n",
        "\n",
        "response = llm.invoke(\"Quais as massas e cargas das partículas que constituem o átomo? Responda no formato JSON em que cada chave seja o nome da partícula\")\n",
        "output = json_parser.invoke(response)\n",
        "\n",
        "print(\"Resposta:\")\n",
        "print(response)\n",
        "print()\n",
        "print(\"Saída do parser:\")\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7yoHDvoRB63"
      },
      "source": [
        "## Encadeamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ZPCQdQx_RB63"
      },
      "outputs": [],
      "source": [
        "chain = prompt_template | llm | StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeZsbiHSRB63",
        "outputId": "70f664b6-af92-45d9-9386-8b5a6ab7b384"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "¡Las playas de Recife tienen tiburones!\n"
          ]
        }
      ],
      "source": [
        "response = chain.invoke({\n",
        "    \"lingua_origem\": \"inglês\",\n",
        "    \"lingua_destino\": \"espanhol\",\n",
        "    \"texto\": \"As praias de Recife tem tubarões!\"\n",
        "})\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7aH7Z046RB63"
      },
      "outputs": [],
      "source": [
        "def translate(texto, lingua_origem, lingua_destino):\n",
        "    response = chain.invoke({\n",
        "        \"lingua_origem\": lingua_origem,\n",
        "        \"lingua_destino\": lingua_destino,\n",
        "        \"texto\": texto\n",
        "    })\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4DZMG-cRB63",
        "outputId": "b102360e-8312-4318-efa1-9d440ab347e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "¡Las playas de Recife tienen tiburones!\n"
          ]
        }
      ],
      "source": [
        "output = translate(\"The beaches of Recife have sharks!\", \"inglês\", \"espanhol\")\n",
        "\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nb1ldp9WRB63"
      },
      "source": [
        "## Exercícios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZxqqIFbRB63"
      },
      "source": [
        "### Exercício 1\n",
        "Crie uma `chain` que a partir de um tópico informado pelo usuário, crie uma piada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "UPKAQrK7TyUu"
      },
      "outputs": [],
      "source": [
        "prompt_template = ChatPromptTemplate.from_template(\"Crie uma piada com o seguinte tema: {texto}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "XqlZyTScUIav"
      },
      "outputs": [],
      "source": [
        "chain = prompt_template | llm | StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSSgxqMNUoFo",
        "outputId": "7d430478-142a-4511-b82b-756770e3a157"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Por que o jogador de futebol sempre leva um lápis para o jogo?\n",
            "\n",
            "Porque ele quer fazer uma boa \"anotação\" no placar! ⚽✏️\n"
          ]
        }
      ],
      "source": [
        "response = chain.invoke({\n",
        "    \"texto\": \"Futebol!\"\n",
        "})\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MnK4ByaRB63"
      },
      "source": [
        "### Exercício 2\n",
        "Crie uma `chain` que classifique o sentimento de um texto de entrada em positivo, neutro ou negativo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_rH9ayoRB63",
        "outputId": "6472b2e2-d2e4-486e-c8a1-5b6a0b2d2fe8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Negativa.\n"
          ]
        }
      ],
      "source": [
        "prompt_template = ChatPromptTemplate.from_template(\"Esse texto {texto} tem conotação Positiva, Negativa ou Neutro? Seja objetivo na resposta.\")\n",
        "\n",
        "chain = prompt_template | llm | StrOutputParser()\n",
        "\n",
        "response = chain.invoke({\n",
        "    \"texto\": \"Você é gordo.!\"\n",
        "})\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H186s1nsRB63"
      },
      "source": [
        "### Exercício 3\n",
        "Crie uma `chain` que gere o código de uma função Python de acordo com a descrição do usuário."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_Chh9DuRB63",
        "outputId": "63defd6e-dec3-4e0b-ee71-6e72bef6cfd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Claro! Aqui está um exemplo de uma calculadora simples em Python que pode realizar operações básicas (adição, subtração, multiplicação e divisão) com duas variáveis:\n",
            "\n",
            "```python\n",
            "def calculadora():\n",
            "    print(\"Bem-vindo à calculadora de duas variáveis!\")\n",
            "    \n",
            "    # Solicita ao usuário as duas variáveis\n",
            "    try:\n",
            "        num1 = float(input(\"Digite o primeiro número: \"))\n",
            "        num2 = float(input(\"Digite o segundo número: \"))\n",
            "    except ValueError:\n",
            "        print(\"Por favor, insira números válidos.\")\n",
            "        return\n",
            "\n",
            "    print(\"Escolha a operação:\")\n",
            "    print(\"1. Adição (+)\")\n",
            "    print(\"2. Subtração (-)\")\n",
            "    print(\"3. Multiplicação (*)\")\n",
            "    print(\"4. Divisão (/)\")\n",
            "\n",
            "    operacao = input(\"Digite o número da operação desejada (1/2/3/4): \")\n",
            "\n",
            "    if operacao == '1':\n",
            "        resultado = num1 + num2\n",
            "        print(f\"{num1} + {num2} = {resultado}\")\n",
            "    elif operacao == '2':\n",
            "        resultado = num1 - num2\n",
            "        print(f\"{num1} - {num2} = {resultado}\")\n",
            "    elif operacao == '3':\n",
            "        resultado = num1 * num2\n",
            "        print(f\"{num1} * {num2} = {resultado}\")\n",
            "    elif operacao == '4':\n",
            "        if num2 != 0:\n",
            "            resultado = num1 / num2\n",
            "            print(f\"{num1} / {num2} = {resultado}\")\n",
            "        else:\n",
            "            print(\"Erro: Divisão por zero não é permitida.\")\n",
            "    else:\n",
            "        print(\"Operação inválida. Por favor, escolha uma operação válida.\")\n",
            "\n",
            "# Chama a função da calculadora\n",
            "calculadora()\n",
            "```\n",
            "\n",
            "### Como funciona:\n",
            "1. O programa solicita que o usuário insira dois números.\n",
            "2. O usuário escolhe uma operação entre adição, subtração, multiplicação ou divisão.\n",
            "3. O programa realiza a operação escolhida e exibe o resultado.\n",
            "4. Em caso de divisão, o programa verifica se o divisor é zero para evitar um erro de divisão por zero.\n",
            "\n",
            "### Para executar o código:\n",
            "- Copie e cole o código em um arquivo Python (por exemplo, `calculadora.py`).\n",
            "- Execute o arquivo usando um interpretador Python (por exemplo, `python calculadora.py`).\n"
          ]
        }
      ],
      "source": [
        "prompt_template = ChatPromptTemplate.from_template(\"Crie um código em {linguagem_de_programacao} que faça {texto}\")\n",
        "\n",
        "chain = prompt_template | llm | StrOutputParser()\n",
        "\n",
        "response = chain.invoke({\"texto\": \"Calculadora de duas variáveis\", \"linguagem_de_programacao\": \"python\"})\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0uqc7EIRB63"
      },
      "source": [
        "### Exercício 4\n",
        "Crie uma `chain` que explique de forma simplificada um tópico geral fornecido pelo usuário e, em seguida, traduza a explicação para inglês. Utilize dois templates encadeados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "DguVPCw0RB63"
      },
      "outputs": [],
      "source": [
        "prompt_template_informacao = ChatPromptTemplate.from_template(\"Explique de forma simplificada sobre {texto}.\")\n",
        "\n",
        "prompt_template_tradução = ChatPromptTemplate.from_template(\"Você é um tradutor de {lingua_origem} para {lingua_destino}. Traduza {texto}.\")\n",
        "\n",
        "chain_info = prompt_template_informacao | llm | StrOutputParser()\n",
        "\n",
        "chain_traducao = prompt_template_tradução | llm | StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKojUzXpuEZr",
        "outputId": "c0d57bac-9cd6-4a2b-abcc-1816233ff28b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Renewable energy is energy that comes from natural sources that are constantly replenished. Unlike fossil fuels, which are limited and polluting, renewable energy sources are more sustainable and less harmful to the environment. The main sources of renewable energy include:\n",
            "\n",
            "1. **Solar**: Captures sunlight and converts it into electricity or heat.\n",
            "2. **Wind**: Uses the power of the wind to generate electricity through turbines.\n",
            "3. **Hydroelectric**: Harnesses the energy of moving water, such as rivers and waterfalls, to produce electricity.\n",
            "4. **Biomass**: Utilizes organic matter (such as plants and waste) to generate energy, either through burning or by converting it into biofuels.\n",
            "5. **Geothermal**: Taps into the heat from the Earth's interior to generate electricity or heat spaces.\n",
            "\n",
            "These sources are important because they help reduce dependence on fossil fuels, decrease greenhouse gas emissions, and promote a more sustainable future.\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import LLMChain, SimpleSequentialChain\n",
        "\n",
        "# Template para explicação\n",
        "explain_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Explique de forma simplificada sobre {texto}.\"\n",
        ")\n",
        "\n",
        "# Template para tradução\n",
        "translate_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Você é um tradutor. Traduza o seguinte texto para inglês: {explicacao}.\"\n",
        ")\n",
        "\n",
        "# Criar os chains individuais\n",
        "explain_chain = LLMChain(llm=llm, prompt=explain_prompt, output_key=\"explicacao\")\n",
        "translate_chain = LLMChain(llm=llm, prompt=translate_prompt, output_key=\"traducao\")\n",
        "\n",
        "# Encadear os chains\n",
        "final_chain = SequentialChain(\n",
        "    chains=[explain_chain, translate_chain],\n",
        "    input_variables=[\"texto\"],       # Entrada inicial\n",
        "    output_variables=[\"traducao\"]    # Saída final\n",
        ")\n",
        "\n",
        "# Executar o chain\n",
        "response = final_chain.run({\n",
        "    \"texto\": \"Energia renovável\"\n",
        "})\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMXmfNz7RB63"
      },
      "source": [
        "### Exercício 5 - Desafio\n",
        "Crie uma `chain` que responda perguntas sobre o CESAR School."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kakKKPqRB63",
        "outputId": "25e16f4e-8988-45f1-cf63-08e1ab0f81ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A CESAR School está localizada em Recife, Pernambuco, Brasil. Fundada pelo CESAR (Centro de Estudos e Sistemas Avançados do Recife), a escola tem como objetivo formar profissionais altamente capacitados nas áreas de tecnologia, design e gestão. \n",
            "\n",
            "Se você está interessado em se especializar e desenvolver suas habilidades, a CESAR School oferece uma variedade de cursos, incluindo graduação, pós-graduação e programas de extensão. Nossos cursos são projetados para atender às demandas do mercado e preparar os alunos para os desafios da indústria. Venha conhecer mais sobre nossas opções e dê o próximo passo na sua carreira!\n"
          ]
        }
      ],
      "source": [
        "prompt_template = ChatPromptTemplate.from_template(\"Você é um funcionário do CESAR School, responda sobre o tópico {texto}. Ao final tente sempre vender os cursos e responde apenas sobre a CESAR School.\")\n",
        "\n",
        "chain = prompt_template | llm | StrOutputParser()\n",
        "\n",
        "response = chain.invoke({\"texto\": \"De onde é a CESAR School?\"})\n",
        "\n",
        "print(response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
